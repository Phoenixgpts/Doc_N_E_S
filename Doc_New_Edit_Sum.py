import streamlit as st
from openai import OpenAI
from docx import Document
from io import BytesIO
import os
import requests
from dotenv import load_dotenv
import tiktoken
from typing import List

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
openai_api_key = os.getenv("OPENAI_API_KEY")

# API í‚¤ ê²€ì¦
if not openai_api_key:
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

st.set_page_config(
    page_title="Document NEW + EDIT + SUM",
    page_icon="ðŸ“„",
)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=openai_api_key)

generation_config = {
    "temperature": 0.4,
    "top_p": 0.95,
}

# ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸ ì„ íƒ
model_selection = st.sidebar.radio("**ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš” :**", ("Phoenix-GPT4o", "Phoenix-GPT4o-Mini"), captions=("ê°€ê²©â†‘/ì„±ëŠ¥â†‘/ì†ë„â†“", "ê°€ê²©â†“/ì„±ëŠ¥â†“/ì†ë„â†‘"))
model_name = "gpt-4" if model_selection == "Phoenix-GPT4o" else "gpt-4o-mini"

st.title("Document NEW + EDIT + SUM")
st.caption("By Phoenix AI")

def split_text(text: str, max_tokens: int = 8000) -> List[str]:
    encoding = tiktoken.get_encoding("cl100k_base")
    tokens = encoding.encode(text)
    chunks = []
    
    for i in range(0, len(tokens), max_tokens):
        chunk = encoding.decode(tokens[i:i + max_tokens])
        chunks.append(chunk)
    
    return chunks

language_prompts = {
    "í•œêµ­ì–´": "ì´ í‚¤ì›Œë“œì— ëŒ€í•œ 2,000ìž ê¸¸ì´ì˜ ë¬¸ì„œë¥¼ í•œêµ­ì–´ë¡œ ìƒì„±í•´ì¤˜.",
    "ì˜ì–´": "Generate a 2,000-character document for this keyword in English.",
    "ì¼ë³¸ì–´": "ã“ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã¤ã„ã¦2,000æ–‡å­—ã®æ—¥æœ¬èªžã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
    "ì¤‘êµ­ì–´": "è¯·ç”¨ä¸­æ–‡ç”Ÿæˆå…³äºŽè¿™ä¸ªå…³é”®è¯çš„2,000å­—æ–‡æ¡£ã€‚",
    "ëŸ¬ì‹œì•„ì–´": "Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð½Ð° 2,000 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð¿Ð¾ ÑÑ‚Ð¾Ð¼Ñƒ ÐºÐ»ÑŽÑ‡ÐµÐ²Ð¾Ð¼Ñƒ ÑÐ»Ð¾Ð²Ñƒ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.",
    "í”„ëž‘ìŠ¤ì–´": "GÃ©nÃ©rez un document de 2,000 caractÃ¨res pour ce mot-clÃ© en franÃ§ais.",
    "ë…ì¼ì–´": "Erstellen Sie ein 2,000 Zeichen langes Dokument fÃ¼r dieses SchlÃ¼sselwort auf Deutsch.",
    "ì´íƒˆë¦¬ì•„ì–´": "Genera un documento di 2,000 caratteri per questa parola chiave in italiano."
}

# 1. Doc-New
st.header("1. Doc-New")
keyword = st.text_input("ìƒì„±í•  ë¬¸ì„œì˜ í‚¤ì›Œë“œë¥¼ ìž…ë ¥í•´ ì£¼ì„¸ìš”:")
output_language_new = st.selectbox("ìƒì„±í•œ ë¬¸ì„œì˜ ì¶œë ¥ ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”", list(language_prompts.keys()), key="new_language")
if st.button("ë¬¸ì„œ ìƒì„±") and keyword:
    with st.spinner("ë¬¸ì„œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ìž…ë‹ˆë‹¤..."):
        system_instruction = language_prompts[output_language_new]
        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_instruction},
                    {"role": "user", "content": keyword}
                ],
                max_tokens=2000,
                **generation_config
            )
            result_text = response.choices[0].message.content.strip()
            st.session_state.result_text = result_text
            st.success(result_text)
        except Exception as e:
            st.error(f"ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# 2. Doc-Edit
st.header("2. Doc-Edit")
uploaded_file_edit = st.file_uploader("ìˆ˜ì •í•  ë¬¸ì„œë¥¼ ì—…ë¡œë“œ í•´ ì£¼ì„¸ìš”", type=["docx"], key="edit_file")
uploaded_link_edit = st.text_input("ìˆ˜ì •í•  ë¬¸ì„œì˜ ë§í¬ë¥¼ ìž…ë ¥í•´ ì£¼ì„¸ìš”:", key="edit_link")

doc_text_edit = ""
if uploaded_file_edit:
    doc_text_edit = "\n".join([para.text for para in Document(uploaded_file_edit).paragraphs])
elif uploaded_link_edit:
    response = requests.get(uploaded_link_edit)
    if response.status_code == 200:
        doc_text_edit = response.text
    else:
        st.error("ë¬¸ì„œ ë§í¬ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if doc_text_edit:
    st.text_area("ë¬¸ì„œ ë‚´ìš©", doc_text_edit, height=300)
    edit_keyword = st.text_input("ìˆ˜ì •í•  í‚¤ì›Œë“œ ë˜ëŠ” ë¬¸ìž¥ì„ ìž…ë ¥í•´ ì£¼ì„¸ìš”:")
    output_language_edit = st.selectbox("ìˆ˜ì •í•œ ë¬¸ì„œì˜ ì¶œë ¥ ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”:", list(language_prompts.keys()), key="edit_language")
    if st.button("ë¬¸ì„œ ìˆ˜ì •") and edit_keyword:
        with st.spinner("ë¬¸ì„œë¥¼ ìˆ˜ì •í•˜ëŠ” ì¤‘ìž…ë‹ˆë‹¤..."):
            system_instruction = language_prompts[output_language_edit]
            chunks = split_text(doc_text_edit)
            edited_chunks = []
            for i, chunk in enumerate(chunks):
                try:
                    response = client.chat.completions.create(
                        model=model_name,
                        messages=[
                            {"role": "system", "content": system_instruction},
                            {"role": "user", "content": f"{edit_keyword}\n\n{chunk}"}
                        ],
                        max_tokens=2000,
                        **generation_config
                    )
                    edited_chunks.append(response.choices[0].message.content.strip())
                    st.progress((i + 1) / len(chunks))
                except Exception as e:
                    st.error(f"ë¬¸ì„œ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (íŒŒíŠ¸ {i+1}): {str(e)}")
                    break
            edited_text = "\n\n".join(edited_chunks)
            st.session_state.edited_text = edited_text
            st.success(edited_text)

# 3. Doc-SUM
st.header("3. Doc-SUM")
uploaded_file_sum = st.file_uploader("ìš”ì•½í•  ë¬¸ì„œë¥¼ ì—…ë¡œë“œ í•´ ì£¼ì„¸ìš”", type=["docx"], key="sum_file")
uploaded_link_sum = st.text_input("ìš”ì•½í•  ë¬¸ì„œì˜ ë§í¬ë¥¼ ìž…ë ¥í•´ ì£¼ì„¸ìš”:", key="sum_link")

doc_text_sum = ""
if uploaded_file_sum:
    doc_text_sum = "\n".join([para.text for para in Document(uploaded_file_sum).paragraphs])
elif uploaded_link_sum:
    response = requests.get(uploaded_link_sum)
    if response.status_code == 200:
        doc_text_sum = response.text
    else:
        st.error("ë¬¸ì„œ ë§í¬ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if doc_text_sum:
    st.text_area("ìš”ì•½í•  ë¬¸ì„œ ë‚´ìš©", doc_text_sum, height=300)
    sum_keyword = st.text_input("ìš”ì•½í•  í‚¤ì›Œë“œ ë˜ëŠ” ë¬¸ìž¥ì„ ìž…ë ¥í•´ ì£¼ì„¸ìš”:")
    output_language_sum = st.selectbox("ìš”ì•½í•œ ë¬¸ì„œì˜ ì¶œë ¥ ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”:", list(language_prompts.keys()), key="sum_language")
    if st.button("ë¬¸ì„œ ìš”ì•½") and sum_keyword:
        with st.spinner("ë¬¸ì„œë¥¼ ìš”ì•½í•˜ëŠ” ì¤‘ìž…ë‹ˆë‹¤..."):
            system_instruction = language_prompts[output_language_sum]
            chunks = split_text(doc_text_sum)
            summarized_chunks = []
            for i, chunk in enumerate(chunks):
                try:
                    response = client.chat.completions.create(
                        model=model_name,
                        messages=[
                            {"role": "system", "content": system_instruction},
                            {"role": "user", "content": f"{sum_keyword}\n\n{chunk}"}
                        ],
                        max_tokens=1000,
                        **generation_config
                    )
                    summarized_chunks.append(response.choices[0].message.content.strip())
                    st.progress((i + 1) / len(chunks))
                except Exception as e:
                    st.error(f"ë¬¸ì„œ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (íŒŒíŠ¸ {i+1}): {str(e)}")
                    break
            
            if len(summarized_chunks) > 1:
                final_summary = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": "Combine the following summaries into one coherent summary:"},
                        {"role": "user", "content": "\n\n".join(summarized_chunks)}
                    ],
                    max_tokens=2000,
                    **generation_config
                )
                summarized_text = final_summary.choices[0].message.content.strip()
            else:
                summarized_text = summarized_chunks[0] if summarized_chunks else ""

            st.session_state.summarized_text = summarized_text
            st.success(summarized_text)
